name: Publish Release to Private Registry

on:
  workflow_call:
    outputs:
      released:
        description: Was the binary published
        value: ${{ jobs.cargo_upload_binary.outputs.released }}
    inputs:
      required_packages:
        type: string
        default: ""
        description: Package that needs to be installed before Rust compilation can happens
      additional_args:
        type: string
        default: ""
        description: Additional arguments to pass to the cargo command
      toolchain:
        type: string
        default: "1.73"
        description: Rust toolchain to install
      release_channel:
        type: string
        default: ""
        description: Hard coded release channel
      profile:
        type: string
        default: "release"
        description: Cargo build profile to use
      login_private_registry:
        type: string
        default: "true"
      skip-test:
        type: boolean
        default: false
        description: Skip the test step
      working-directory:
        type: string
        default: "."
        description: Working directory to run the cargo command
      additional_script:
        type: string
        default: ""
        description: Additional script to run before the additional packages
      matrix_file:
        type: string
        default: ".github/workflows/matrix.json"
        description: "Matrix file to load"
      custom_cargo_commands:
        type: string
        default: ""
        description: Cusom cargo commands that will be run after login
      post_build_additional_script:
        type: string
        default: ""
        description: Post Build Additional script to run after the additional packages
      sign_build:
        type: string
        default: "false"
        description: Should the binary bin be signed

env:
  CARGO_TERM_COLOR: always
  CARGO_NET_GIT_FETCH_WITH_CLI: true
  CARGO_HTTP_USER_AGENT: "shipyard ${{ secrets.CARGO_PRIVATE_REGISTRY_TOKEN }}"

jobs:
  matrix:
    name: Build Matrix for binary release
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    runs-on: "ubuntu-latest"
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      - name: Create and set Build Matrix from matrix.json
        id: set-matrix
        shell: bash
        run: |
          MATRIX=$(jq -c . < ${{ inputs.matrix_file }} | tr -d '^J')
          echo matrix=$MATRIX >> $GITHUB_OUTPUT
  cargo_upload_binary:
    name: Release new version as binary
    strategy:
      matrix:
        os: ${{ fromJson(needs.matrix.outputs.matrix).os }}
    outputs:
      released: ${{ steps.check_exists.outputs.exists == 'false' && 'true' || 'false' }}
    runs-on: ${{ matrix.os.name }}${{ matrix.os.runner_flavour }}
    needs:
      - matrix
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Derive Release Channel
        id: extract_branch
        shell: bash
        env:
          ACTION_RC: ${{ inputs.release_channel }}
        run: |
          BRANCH_NAME=${GITHUB_REF#refs/heads/}
          if [ "$BRANCH_NAME" == "alpha" ] ; then
            RELEASE_CHANNEL=alpha
          elif [ "$BRANCH_NAME" == "beta" ] ; then
            RELEASE_CHANNEL=beta
          elif [ "$BRANCH_NAME" == "prod" ] ; then
            RELEASE_CHANNEL=prod
          fi
          echo release_channel=${ACTION_RC:-${RELEASE_CHANNEL:-nightly}}$RELEASE_CHANNEL >> $GITHUB_OUTPUT

      - uses: SebRollen/toml-action@v1.0.2
        id: read_version
        with:
          file: "${{ inputs.working-directory }}/Cargo.toml"
          field: "package.version"

      - uses: SebRollen/toml-action@v1.0.2
        id: read_name
        with:
          file: "${{ inputs.working-directory }}/Cargo.toml"
          field: "package.name"

      - uses: ForesightMiningSoftwareCorporation/azure-blob-storage-check-exists@v1
        id: check_exists
        with:
          container_name: ${{ vars.ARTIFACTS_CONTAINER }}
          connection_string: ${{ secrets.ARTIFACTS_CONNECTION_STRING }}
          blob_name: ${{ steps.read_name.outputs.value }}/${{ steps.extract_branch.outputs.release_channel }}/${{ steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}${{ matrix.os.extension }}

      - uses: ForesightMiningSoftwareCorporation/azure-blob-storage-check-exists@v1
        id: check_signed_exists
        if: inputs.sign_build == 'true'
        with:
          container_name: ${{ vars.ARTIFACTS_CONTAINER }}
          connection_string: ${{ secrets.ARTIFACTS_CONNECTION_STRING }}
          blob_name: ${{ steps.read_name.outputs.value }}/${{ steps.extract_branch.outputs.release_channel }}/${{ steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}-signed${{ matrix.os.extension }}

      - name: Cache Dependencies
        if: steps.check_exists.outputs.exists != 'true'
        uses: Swatinem/rust-cache@v2
        with:
          env-vars: ""
          save-if: ${{ github.ref == 'refs/heads/main' }}

      - uses: dtolnay/rust-toolchain@master
        if: steps.check_exists.outputs.exists != 'true'
        with:
          toolchain: ${{ inputs.toolchain }}

      - uses: ForesightMiningSoftwareCorporation/github/.github/actions/login-private-registry@v1
        if: steps.check_exists.outputs.exists != 'true'
        with:
          private_key: ${{ secrets.CARGO_PRIVATE_REGISTRY_SSH_PRIVATE_KEY }}
          host: ${{ secrets.CARGO_PRIVATE_REGISTRY_HOST }}
          name: ${{ secrets.CARGO_PRIVATE_REGISTRY_NAME }}
          token: ${{ secrets.CARGO_PRIVATE_REGISTRY_TOKEN }}
          additional_private_keys: |
            ${{ secrets.FSE_SSH_PRIVATE_KEY }}
            ${{ secrets.BEVY_CLIPMAP_SSH_PRIVATE_KEY }}
            ${{ secrets.DAG_TABLES_SSH_PRIVATE_KEY }}

      - name: Additional Linux Script from matrix
        if: steps.check_exists.outputs.exists != 'true' && matrix.os.additional_script != '' && matrix.os.name == 'ubuntu-latest'
        working-directory: ${{ inputs.working-directory }}
        env:
          CRATE_NAME: ${{ steps.read_name.outputs.value }}
          CRATE_VERSION: ${{ steps.read_version.outputs.value }}
          RELEASE_CHANNEL: ${{ steps.extract_branch.outputs.release_channel }}
        run: ${{ matrix.os.additional_script }}
        shell: bash

      - name: Additional Linux Script from input if not matrix
        if: steps.check_exists.outputs.exists != 'true' && matrix.os.additional_script == '' && inputs.additional_script != '' && matrix.os.name == 'ubuntu-latest'
        env:
          CRATE_NAME: ${{ steps.read_name.outputs.value }}
          CRATE_VERSION: ${{ steps.read_version.outputs.value }}
          RELEASE_CHANNEL: ${{ steps.extract_branch.outputs.release_channel }}
        working-directory: ${{ inputs.working-directory }}
        run: ${{ inputs.additional_script }}
        shell: bash

      - name: Additional Windows Script from matrix
        if: steps.check_exists.outputs.exists != 'true' && matrix.os.additional_script != '' && matrix.os.name == 'windows-latest'
        env:
          CRATE_NAME: ${{ steps.read_name.outputs.value }}
          CRATE_VERSION: ${{ steps.read_version.outputs.value }}
          RELEASE_CHANNEL: ${{ steps.extract_branch.outputs.release_channel }}
        working-directory: ${{ inputs.working-directory }}
        run: ${{ matrix.os.additional_script }}
        shell: pwsh

      - name: Additional Windows Script from input if not matrix
        if: steps.check_exists.outputs.exists != 'true' && matrix.os.additional_script == '' && inputs.additional_script != '' && matrix.os.name == 'windows-latest'
        env:
          CRATE_NAME: ${{ steps.read_name.outputs.value }}
          CRATE_VERSION: ${{ steps.read_version.outputs.value }}
          RELEASE_CHANNEL: ${{ steps.extract_branch.outputs.release_channel }}
        working-directory: ${{ inputs.working-directory }}
        run: ${{ inputs.additional_script }}
        shell: pwsh

      - name: Update Packages
        if: steps.check_exists.outputs.exists != 'true' && inputs.required_packages != '' && matrix.os.name == 'ubuntu-latest'
        run: sudo apt-get update -yq && sudo apt-get install -yq --no-install-recommends ${{ inputs.required_packages }}

      - name: Run custom cargo command
        if: steps.check_exists.outputs.exists != 'true' && inputs.custom_cargo_commands != ''
        shell: bash
        working-directory: ${{ inputs.working-directory }}
        run: ${{ inputs.custom_cargo_commands }}

      - name: Build Binary
        shell: bash
        if: steps.check_exists.outputs.exists != 'true'
        working-directory: ${{ inputs.working-directory }}
        run: cargo build --profile ${{ inputs.profile }} --target=${{ matrix.os.arch }} ${{ inputs.additional_args }}

      - name: Copy to bin folder linux
        if: matrix.os.name == 'ubuntu-latest' && steps.check_exists.outputs.exists != 'true'
#        `cargo build` put build inside of the workspace root target dir. If using working-drectory inside of a non-workspace repo this will not work anymore
#        working-directory: ${{ inputs.working-directory }}
        shell: bash
        run: |
          artifacts_dir=${{ runner.temp }}/bin_output/${{ steps.read_name.outputs.value }}/${{ steps.extract_branch.outputs.release_channel }}
          mkdir -p $artifacts_dir
          cp target/${{ matrix.os.arch }}/${{ inputs.profile }}/${{ steps.read_name.outputs.value }} $artifacts_dir/${{ steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}${{ matrix.os.extension }}
          sha512sum $artifacts_dir/${{ steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}${{ matrix.os.extension }} | awk '{ print $1 }' >> $artifacts_dir/${{ steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}${{ matrix.os.extension }}-sha-512.txt

      - name: Copy to bin folder windows
        if: matrix.os.name == 'windows-latest' && steps.check_exists.outputs.exists != 'true'
        shell: pwsh
        run: |
          $Out = New-Item -Path "${{ runner.temp }}\bin_output\${{ steps.read_name.outputs.value }}\${{ steps.extract_branch.outputs.release_channel }}" -ItemType "directory"
          Copy-Item target\${{ matrix.os.arch }}\${{ inputs.profile }}\${{ steps.read_name.outputs.value }}${{ matrix.os.extension }} $Out\${{  steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}${{ matrix.os.extension }}
          $hash = Get-FileHash "$Out\${{  steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}${{ matrix.os.extension }}" -Algorithm SHA512
          echo $hash.Hash >> "$Out\${{  steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}-sha512.txt"

      - name: Additional Post build Linux Script from matrix
        if: matrix.os.post_build_additional_script != '' && matrix.os.name == 'ubuntu-latest' && steps.check_exists.outputs.exists != 'true'
        working-directory: ${{ inputs.working-directory }}
        env:
          CRATE_NAME: ${{ steps.read_name.outputs.value }}
          CRATE_VERSION: ${{ steps.read_version.outputs.value }}
          RELEASE_CHANNEL: ${{ steps.extract_branch.outputs.release_channel }}
          TEMP_DIR: ${{ runner.temp }}
        run: ${{ matrix.os.post_build_additional_script }}
        shell: bash

      - name: Additional Post build Linux Script from input if not matrix
        if: matrix.os.post_build_additional_script == '' && inputs.post_build_additional_script != '' && matrix.os.name == 'ubuntu-latest' && steps.check_exists.outputs.exists != 'true'
        env:
          CRATE_NAME: ${{ steps.read_name.outputs.value }}
          CRATE_VERSION: ${{ steps.read_version.outputs.value }}
          RELEASE_CHANNEL: ${{ steps.extract_branch.outputs.release_channel }}
          TEMP_DIR: ${{ runner.temp }}
        working-directory: ${{ inputs.working-directory }}
        run: ${{ inputs.post_build_additional_script }}
        shell: bash

      - name: Additional Post build Windows Script from matrix
        if: matrix.os.post_build_additional_script != '' && matrix.os.name == 'windows-latest' && steps.check_exists.outputs.exists != 'true'
        env:
          CRATE_NAME: ${{ steps.read_name.outputs.value }}
          CRATE_VERSION: ${{ steps.read_version.outputs.value }}
          RELEASE_CHANNEL: ${{ steps.extract_branch.outputs.release_channel }}
          TEMP_DIR: ${{ runner.temp }}
        working-directory: ${{ inputs.working-directory }}
        run: ${{ matrix.os.post_build_additional_script }}
        shell: pwsh

      - name: Additional Post build Windows Script from input if not matrix
        if: matrix.os.post_build_additional_script == '' && inputs.post_build_additional_script != '' && matrix.os.name == 'windows-latest' && steps.check_exists.outputs.exists != 'true'
        env:
          CRATE_NAME: ${{ steps.read_name.outputs.value }}
          CRATE_VERSION: ${{ steps.read_version.outputs.value }}
          RELEASE_CHANNEL: ${{ steps.extract_branch.outputs.release_channel }}
          TEMP_DIR: ${{ runner.temp }}
        working-directory: ${{ inputs.working-directory }}
        run: ${{ inputs.post_build_additional_script }}
        shell: pwsh

      - name: Azure Blob Upload
        if: steps.check_exists.outputs.exists != 'true'
        uses: LanceMcCarthy/Action-AzureBlobUpload@v2.2.1
        with:
          container_name: ${{ vars.ARTIFACTS_CONTAINER }}
          connection_string: ${{ secrets.ARTIFACTS_CONNECTION_STRING }}
          source_folder: ${{ runner.temp }}/bin_output
          delete_if_exists: true

      - name: Generate Expiry for SAS Url
        if: steps.check_signed_exists.outputs.exists != 'true' && inputs.sign_build == 'true'
        shell: bash
        id: sas-expiry
        run: |
          echo "expiry=$(date -u -d "30 minutes" '+%Y-%m-%dT%H:%MZ')" >> $GITHUB_OUTPUT

      - name: Generate SAS Url for binary signing
        if: steps.check_signed_exists.outputs.exists != 'true' && inputs.sign_build == 'true'
        shell: bash
        id: sas-url
        run: |
          sas=$(az storage blob generate-sas --connection-string "${{ secrets.ARTIFACTS_CONNECTION_STRING }}" --container-name ${{ vars.ARTIFACTS_CONTAINER }} --name ${{ steps.read_name.outputs.value }}/${{ steps.extract_branch.outputs.release_channel }}/${{ steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}${{ matrix.os.extension }} --permissions r --expiry ${{ steps.sas-expiry.outputs.expiry }} --https-only --full-uri --output tsv)
          echo "sas=$sas" >> $GITHUB_OUTPUT

      - name: Retrieve signing secret from Vault
        if: steps.check_signed_exists.outputs.exists != 'true' && inputs.sign_build == 'true'
        id: import-signing-secrets
        uses: hashicorp/vault-action@v2.7.3
        with:
          method: jwt
          url: ${{ vars.VAULT_ADDR }}
          path: github
          role: whirlpool-installer
          secrets: |
            kv-v2/data/whirlpool/signer PAT_TOKEN | WHIRLPOOL_SIGNER_PAT_TOKEN ;
            kv-v2/data/whirlpool/signer REPOSITORY | WHIRLPOOL_SIGNER_REPOSITORY ;

      - run: npm install adm-zip
        if: steps.check_signed_exists.outputs.exists != 'true' && inputs.sign_build == 'true'
      - name: Trigger signer workflow
        uses: actions/github-script@v7
        id: signer-workflow
        if: steps.check_signed_exists.outputs.exists != 'true' && inputs.sign_build == 'true'
        with:
          github-token: ${{ steps.import-signing-secrets.outputs.WHIRLPOOL_SIGNER_PAT_TOKEN }}
          script: |
            const AdmZip = require('adm-zip');
            const fs = require('fs');
            const MAX_RETRY=7;
            const RETRY_TIMEOUT_S = 5 ;
            const now = new Date();
            
            const wait = (ms) => new Promise((res) => setTimeout(res, ms));
            
            const callWithRetry = async (fn, max_retry = MAX_RETRY, retry_timeout = RETRY_TIMEOUT_S * 1000, depth = 0) => {
                try {
                    const out = await fn();
                    if (out === undefined || out === null || (Array.isArray(out) && out.length === 0)) {
                        await wait(retry_timeout);
                        return callWithRetry(fn, max_retry, retry_timeout, depth + 1);
                    }
                    return out;
                } catch(e) {
                    if (depth > max_retry) {
                        throw e;
                    }
                    await wait(retry_timeout);
                    return callWithRetry(fn, max_retry, retry_timeout, depth + 1);
                }
            }
            
            const getWorkflowId = async (workflow_name) => {
                const _fetchWorkflow = async () => {
                    const workflows = await github.rest.actions.listWorkflowRuns({
                        owner: gh_info[0],
                        repo: gh_info[1],
                        workflow_id: "sign_file.yaml",
                        created: `>${now.toISOString()}`,
                    });
                    return workflows.data.workflow_runs.find(w => w.name === workflow_name);
                };
                const workflow = await callWithRetry(_fetchWorkflow);
                return workflow && workflow.id;
            }
            
            const workflow_final_status = [
                "completed",
                "cancelled",
                "failure",
                "neutral",
                "skipped",
                "stale",
                "success",
                "timed_out",
            ]
            
            const waitForWorkflowRunCompletion = async (run_id) => {
                const _waitForWorkflowRunCompletion = async () => {
                  const workflow = await github.rest.actions.getWorkflowRun({
                      owner: gh_info[0],
                      repo: gh_info[1],
                      run_id,
                  });
                    if (workflow && workflow_final_status.includes(workflow.data.status)) {
                        return workflow.data;
                    }
                    return null;
                };
                return await callWithRetry(_waitForWorkflowRunCompletion, 60, 60);
            }
            
            const getWorkflowArtifact = async (run_id, artifact_name) => {
               const _getWorkflowArtifact = async () => {
                   const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                       owner: gh_info[0],
                       repo: gh_info[1],
                       run_id,
                   })
                   if (!artifacts) return null;
                   return artifacts.data.artifacts.find(a => a.name === artifact_name);
               }
               return await callWithRetry(_getWorkflowArtifact);
            }
            
            const downloadArtifact = async (artifact_id, download_path) => {
               const zip = await github.rest.actions.downloadArtifact({
                   owner: gh_info[0],
                   repo: gh_info[1],
                   artifact_id,
                   archive_format: "zip"
               });
               fs.mkdirSync(download_path, { recursive: true });
               const adm = new AdmZip(Buffer.from(zip.data));
               adm.extractAllTo(download_path, true);
            } 
            
            // Get data
            const gh_info = "${{ steps.import-signing-secrets.outputs.WHIRLPOOL_SIGNER_REPOSITORY }}".split("/");
            const artifact_sas = "${{ steps.sas-url.outputs.sas }}";
            const artifact_name = "${{ steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}-signed${{ matrix.os.extension }}";
            const gh_artifact_name = "signed_artifacts";
            const temp_dir = String.raw`${{ runner.temp }}`;
            const dir_separator = temp_dir.indexOf("\\") == -1 ? "/" : "\\";
            const download_path = `${temp_dir}${dir_separator}signed_artifacts${dir_separator}${{ steps.read_name.outputs.value }}${dir_separator}${{ steps.extract_branch.outputs.release_channel }}`;
            const repository = "${{ github.repository }}";
            const run_id = "${{ github.run_id }}";
            
            // 1. Dispatch the workflow
            await github.rest.actions.createWorkflowDispatch({
                owner: gh_info[0],
                repo: gh_info[1],
                workflow_id: "sign_file.yaml",
                ref: "download-from-sas",
                inputs: {
                    artifact_sas: artifact_sas,
                    artifact_name: artifact_name,
                    source_repository: repository,
                    source_run_id: run_id
                }
            });
            // 2. Get the workflow id
            const workflow_id = await getWorkflowId(`Sign ${artifact_name} ${repository} ${run_id}`);
            // 3. Wait for the workflow_completion
            const completed_workflow = await waitForWorkflowRunCompletion(workflow_id);
            // 4. Load workflow artifact
            const artifact = await getWorkflowArtifact(workflow_id, gh_artifact_name);
            // 5. Download artifact
            await downloadArtifact(artifact.id, download_path);
            return {
                status: completed_workflow.status,
                conclusion: completed_workflow.conclusion,
                url: completed_workflow.url,
                id: completed_workflow.id,
            }

      - name: Generate signed artifacts checksum linux
        if: matrix.os.name == 'ubuntu-latest' && steps.check_signed_exists.outputs.exists != 'true' && inputs.sign_build == 'true'
        shell: bash
        run: |
          artifacts_dir=${{ runner.temp }}/signed_artifacts/${{ steps.read_name.outputs.value }}/${{ steps.extract_branch.outputs.release_channel }}
          sha512sum $artifacts_dir/${{ steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}-signed${{ matrix.os.extension }} | awk '{ print $1 }' >> $artifacts_dir/${{ steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}${{ matrix.os.extension }}-signed-sha-512.txt

      - name: Generate signed artifacts checksum windows
        if: matrix.os.name == 'windows-latest' && steps.check_signed_exists.outputs.exists != 'true' && inputs.sign_build == 'true'
        shell: pwsh
        run: |
          $hash = Get-FileHash "${{ runner.temp }}\signed_artifacts\${{ steps.read_name.outputs.value }}\${{ steps.extract_branch.outputs.release_channel }}\${{  steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}-signed${{ matrix.os.extension }}" -Algorithm SHA512
          echo $hash.Hash >> "${{ runner.temp }}\signed_artifacts\${{ steps.read_name.outputs.value }}\${{ steps.extract_branch.outputs.release_channel }}\${{  steps.read_name.outputs.value }}-${{ matrix.os.arch }}-${{ inputs.toolchain }}-v${{ steps.read_version.outputs.value }}-signed-sha512.txt"
      - name: Upload signed artifacts to Azure Blob Upload
        if: steps.check_signed_exists.outputs.exists != 'true' && inputs.sign_build == 'true'
        uses: LanceMcCarthy/Action-AzureBlobUpload@v2.2.1
        with:
          container_name: ${{ vars.ARTIFACTS_CONTAINER }}
          connection_string: ${{ secrets.ARTIFACTS_CONNECTION_STRING }}
          source_folder: ${{ runner.temp }}/signed_artifacts
          delete_if_exists: true
