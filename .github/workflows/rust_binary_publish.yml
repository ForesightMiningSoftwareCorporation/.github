name: Publish Release to Private Registry

on:
  workflow_dispatch:
    outputs:
      released:
        description: Was the binary published
        value: "true"
    inputs:
      required_packages:
        type: string
        default: ""
        description: Package that needs to be installed before Rust compilation can happens
      additional_args:
        type: string
        default: ""
        description: Additional arguments to pass to the cargo command
      toolchain:
        type: string
        default: "1.73"
        description: Rust toolchain to install
      release_channel:
        type: string
        default: ""
        description: Hard coded release channel
      profile:
        type: string
        default: "release"
        description: Cargo build profile to use
      working_directory:
        type: string
        default: "."
        description: Working directory to run the cargo command
      additional_script:
        type: string
        default: ""
        description: Additional script to run before the additional packages
      custom_cargo_commands:
        type: string
        default: ""
        description: Custom cargo commands that will be run after login
      post_build_additional_script:
        type: string
        default: ""
        description: Post Build Additional script to run after the additional packages
      sign_build:
        type: string
        default: "false"
        description: Should the binary bin be signed
  workflow_call:
    outputs:
      released:
        description: Was the binary published
        value: "true"
    inputs:
      required_packages:
        type: string
        default: ""
        description: Package that needs to be installed before Rust compilation can happens
      additional_args:
        type: string
        default: ""
        description: Additional arguments to pass to the cargo command
      toolchain:
        type: string
        default: "1.73"
        description: Rust toolchain to install
      release_channel:
        type: string
        default: ""
        description: Hard coded release channel
      profile:
        type: string
        default: "release"
        description: Cargo build profile to use
      working_directory:
        type: string
        default: "."
        description: Working directory to run the cargo command
      additional_script:
        type: string
        default: ""
        description: Additional script to run before the additional packages
      custom_cargo_commands:
        type: string
        default: ""
        description: Custom cargo commands that will be run after login
      post_build_additional_script:
        type: string
        default: ""
        description: Post Build Additional script to run after the additional packages
      sign_build:
        type: string
        default: "false"
        description: Should the binary bin be signed

env:
  CARGO_TERM_COLOR: always
  CARGO_NET_GIT_FETCH_WITH_CLI: true
  CARGO_HTTP_USER_AGENT: "shipyard ${{ secrets.CARGO_PRIVATE_REGISTRY_TOKEN }}"

jobs:
  derive_info:
    name: Derive build information from key files
    outputs:
      toolchain: ${{ steps.derive_info.outputs.toolchain }}
      release_channel: ${{ steps.derive_info.outputs.release_channel }}
      package: ${{ steps.derive_info.outputs.package }}
      version: ${{ steps.derive_info.outputs.version }}
    runs-on: "ubuntu-latest"
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          sparse-checkout: |
            rust-toolchain.toml
            ${{ inputs.matrix_file }}
            ${{ inputs.working_directory }}/Cargo.toml
      - id: derive_info
        name: Derive info
        shell: bash
        env:
          ACTION_RC: ${{ inputs.release_channel }}
          DEFAULT_TOOLCHAIN: ${{ inputs.toolchain}}
        run: |
          BRANCH_NAME=${GITHUB_REF#refs/heads/}
          if [ "$BRANCH_NAME" == "alpha" ] ; then
            RELEASE_CHANNEL=alpha
          elif [ "$BRANCH_NAME" == "beta" ] ; then
            RELEASE_CHANNEL=beta
          elif [ "$BRANCH_NAME" == "prod" ] ; then
            RELEASE_CHANNEL=prod
          fi
          echo release_channel=${ACTION_RC:-${RELEASE_CHANNEL:-nightly}} >> $GITHUB_OUTPUT
          echo toolchain=$(yq -p toml '.toolchain.channel' < rust-toolchain.toml || echo '$DEFAULT_TOOLCHAIN') >> $GITHUB_OUTPUT
          echo package=$(yq -p toml '.package.name' < ${{ inputs.working_directory }}/Cargo.toml) >> $GITHUB_OUTPUT
          echo version=$(yq -p toml '.package.version' < ${{ inputs.working_directory }}/Cargo.toml) >> $GITHUB_OUTPUT

  cargo_upload_binary:
    name: Release new version as binary
    strategy:
      matrix:
        os:
          - arch: x86_64-pc-windows-msvc
            name: windows-latest
            runner_flavour: -16-cores-custom
            extension: ".exe"
    runs-on: ${{ matrix.os.name }}${{ matrix.os.runner_flavour }}
    needs:
      - derive_info
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Cache Dependencies
        uses: Swatinem/rust-cache@v2
        with:
          env-vars: ""
          save-if: ${{ github.ref == 'refs/heads/main' }}

      - uses: dtolnay/rust-toolchain@master
        with:
          toolchain: ${{ needs.derive_info.outputs.toolchain }}

      - uses: ForesightMiningSoftwareCorporation/github/.github/actions/login-private-registry@v1
        with:
          private_key: ${{ secrets.CARGO_PRIVATE_REGISTRY_SSH_PRIVATE_KEY }}
          host: ${{ secrets.CARGO_PRIVATE_REGISTRY_HOST }}
          name: ${{ secrets.CARGO_PRIVATE_REGISTRY_NAME }}
          token: ${{ secrets.CARGO_PRIVATE_REGISTRY_TOKEN }}
          additional_private_keys: |
            ${{ secrets.FSE_SSH_PRIVATE_KEY }}
            ${{ secrets.BEVY_CLIPMAP_SSH_PRIVATE_KEY }}
            ${{ secrets.DAG_TABLES_SSH_PRIVATE_KEY }}

      - name: Additional Linux Script from matrix
        if: matrix.os.additional_script != '' && matrix.os.name == 'ubuntu-latest'
        working-directory: ${{ inputs.working_directory }}
        env:
          CRATE_NAME: ${{ needs.derive_info.outputs.package }}
          CRATE_VERSION: ${{ needs.derive_info.outputs.version }}
          RELEASE_CHANNEL: ${{ needs.derive_info.outputs.release_channel }}
        run: ${{ matrix.os.additional_script }}
        shell: bash

      - name: Additional Linux Script from input if not matrix
        if: matrix.os.additional_script == '' && inputs.additional_script != '' && matrix.os.name == 'ubuntu-latest'
        env:
          CRATE_NAME: ${{ needs.derive_info.outputs.package }}
          CRATE_VERSION: ${{ needs.derive_info.outputs.version }}
          RELEASE_CHANNEL: ${{ needs.derive_info.outputs.release_channel }}
        working-directory: ${{ inputs.working_directory }}
        run: ${{ inputs.additional_script }}
        shell: bash

      - name: Additional Windows Script from matrix
        if: matrix.os.additional_script != '' && matrix.os.name == 'windows-latest'
        env:
          CRATE_NAME: ${{ needs.derive_info.outputs.package }}
          CRATE_VERSION: ${{ needs.derive_info.outputs.version }}
          RELEASE_CHANNEL: ${{ needs.derive_info.outputs.release_channel }}
        working-directory: ${{ inputs.working_directory }}
        run: ${{ matrix.os.additional_script }}
        shell: pwsh

      - name: Additional Windows Script from input if not matrix
        if: matrix.os.additional_script == '' && inputs.additional_script != '' && matrix.os.name == 'windows-latest'
        env:
          CRATE_NAME: ${{ needs.derive_info.outputs.package }}
          CRATE_VERSION: ${{ needs.derive_info.outputs.version }}
          RELEASE_CHANNEL: ${{ needs.derive_info.outputs.release_channel }}
        working-directory: ${{ inputs.working_directory }}
        run: ${{ inputs.additional_script }}
        shell: pwsh

      - name: Update Packages
        if: inputs.required_packages != '' && matrix.os.name == 'ubuntu-latest'
        run: sudo apt-get update -yq && sudo apt-get install -yq --no-install-recommends ${{ inputs.required_packages }}

      - name: Run custom cargo command
        if: inputs.custom_cargo_commands != ''
        shell: bash
        working-directory: ${{ inputs.working_directory }}
        run: ${{ inputs.custom_cargo_commands }}

      - name: Build Binary
        shell: bash
        working-directory: ${{ inputs.working_directory }}
        run: cargo build --profile ${{ inputs.profile }} --target=${{ matrix.os.arch }} ${{ inputs.additional_args }}
        env:
          CARGO_TARGET_DIR: target

      - name: Copy to bin folder linux
        if: matrix.os.name == 'ubuntu-latest'
        #        `cargo build` put build inside of the workspace root target dir. If using working-drectory inside of a non-workspace repo this will not work anymore
        #        working-directory: ${{ inputs.working_directory }}
        shell: bash
        working-directory: ${{ inputs.working_directory }}
        run: |
          artifacts_dir=${{ runner.temp }}/bin_output/${{ needs.derive_info.outputs.package }}/${{ needs.derive_info.outputs.release_channel }}
          mkdir -p $artifacts_dir
          cp target/${{ matrix.os.arch }}/${{ inputs.profile }}/${{ needs.derive_info.outputs.package }} $artifacts_dir/${{ needs.derive_info.outputs.package }}-${{ matrix.os.arch }}-${{ needs.derive_info.outputs.toolchain}}-v${{ needs.derive_info.outputs.version }}${{ matrix.os.extension }}
          sha512sum $artifacts_dir/${{ needs.derive_info.outputs.package }}-${{ matrix.os.arch }}-${{ needs.derive_info.outputs.toolchain}}-v${{ needs.derive_info.outputs.version }}${{ matrix.os.extension }} | awk '{ print $1 }' >> $artifacts_dir/${{ needs.derive_info.outputs.package }}-${{ matrix.os.arch }}-${{ needs.derive_info.outputs.toolchain}}-v${{ needs.derive_info.outputs.version }}${{ matrix.os.extension }}-sha-512.txt

      - name: Copy to bin folder windows
        if: matrix.os.name == 'windows-latest'
        shell: pwsh
        working-directory: ${{ inputs.working_directory }}
        run: |
          $Out = New-Item -Path "${{ runner.temp }}\bin_output\${{ needs.derive_info.outputs.package }}\${{ needs.derive_info.outputs.release_channel }}" -ItemType "directory"
          Copy-Item target\${{ matrix.os.arch }}\${{ inputs.profile }}\${{ needs.derive_info.outputs.package }}${{ matrix.os.extension }} $Out\${{  needs.derive_info.outputs.package }}-${{ matrix.os.arch }}-${{ needs.derive_info.outputs.toolchain}}-v${{ needs.derive_info.outputs.version }}${{ matrix.os.extension }}
          $hash = Get-FileHash "$Out\${{  needs.derive_info.outputs.package }}-${{ matrix.os.arch }}-${{ needs.derive_info.outputs.toolchain}}-v${{ needs.derive_info.outputs.version }}${{ matrix.os.extension }}" -Algorithm SHA512
          echo $hash.Hash >> "$Out\${{  needs.derive_info.outputs.package }}-${{ matrix.os.arch }}-${{ needs.derive_info.outputs.toolchain}}-v${{ needs.derive_info.outputs.version }}-sha512.txt"

      - name: Additional Post build Linux Script from matrix
        if: matrix.os.post_build_additional_script != '' && matrix.os.name == 'ubuntu-latest'
        working-directory: ${{ inputs.working_directory }}
        env:
          CRATE_NAME: ${{ needs.derive_info.outputs.package }}
          CRATE_VERSION: ${{ needs.derive_info.outputs.version }}
          RELEASE_CHANNEL: ${{ needs.derive_info.outputs.release_channel }}
          TEMP_DIR: ${{ runner.temp }}
        run: ${{ matrix.os.post_build_additional_script }}
        shell: bash

      - name: Additional Post build Linux Script from input if not matrix
        if: matrix.os.post_build_additional_script == '' && inputs.post_build_additional_script != '' && matrix.os.name == 'ubuntu-latest'
        env:
          CRATE_NAME: ${{ needs.derive_info.outputs.package }}
          CRATE_VERSION: ${{ needs.derive_info.outputs.version }}
          RELEASE_CHANNEL: ${{ needs.derive_info.outputs.release_channel }}
          TEMP_DIR: ${{ runner.temp }}
        working-directory: ${{ inputs.working_directory }}
        run: ${{ inputs.post_build_additional_script }}
        shell: bash

      - name: Additional Post build Windows Script from matrix
        if: matrix.os.post_build_additional_script != '' && matrix.os.name == 'windows-latest'
        env:
          CRATE_NAME: ${{ needs.derive_info.outputs.package }}
          CRATE_VERSION: ${{ needs.derive_info.outputs.version }}
          RELEASE_CHANNEL: ${{ needs.derive_info.outputs.release_channel }}
          TEMP_DIR: ${{ runner.temp }}
        working-directory: ${{ inputs.working_directory }}
        run: ${{ matrix.os.post_build_additional_script }}
        shell: pwsh

      - name: Additional Post build Windows Script from input if not matrix
        if: matrix.os.post_build_additional_script == '' && inputs.post_build_additional_script != '' && matrix.os.name == 'windows-latest'
        env:
          CRATE_NAME: ${{ needs.derive_info.outputs.package }}
          CRATE_VERSION: ${{ needs.derive_info.outputs.version }}
          RELEASE_CHANNEL: ${{ needs.derive_info.outputs.release_channel }}
          TEMP_DIR: ${{ runner.temp }}
        working-directory: ${{ inputs.working_directory }}
        run: ${{ inputs.post_build_additional_script }}
        shell: pwsh

      - name: Azure Blob Upload
        uses: LanceMcCarthy/Action-AzureBlobUpload@v2.2.1
        with:
          container_name: ${{ vars.ARTIFACTS_CONTAINER }}
          connection_string: ${{ secrets.ARTIFACTS_CONNECTION_STRING }}
          source_folder: ${{ runner.temp }}/bin_output
          delete_if_exists: true

      - name: Generate Expiry for SAS Url
        if: inputs.sign_build == 'true'
        shell: bash
        id: sas-expiry
        run: |
          echo "expiry=$(date -u -d "120 minutes" '+%Y-%m-%dT%H:%MZ')" >> $GITHUB_OUTPUT

      - name: Generate SAS Url for binary signing
        if: inputs.sign_build == 'true'
        shell: bash
        id: sas-url
        run: |
          sas=$(az storage blob generate-sas --connection-string "${{ secrets.ARTIFACTS_CONNECTION_STRING }}" --container-name ${{ vars.ARTIFACTS_CONTAINER }} --name ${{ needs.derive_info.outputs.package }}/${{ needs.derive_info.outputs.release_channel }}/${{ needs.derive_info.outputs.package }}-${{ matrix.os.arch }}-${{ needs.derive_info.outputs.toolchain}}-v${{ needs.derive_info.outputs.version }}${{ matrix.os.extension }} --permissions r --expiry ${{ steps.sas-expiry.outputs.expiry }} --https-only --full-uri --output tsv)
          echo "sas=$sas" >> $GITHUB_OUTPUT

      - name: Retrieve signing secret from Vault
        if: inputs.sign_build == 'true'
        id: import-signing-secrets
        uses: hashicorp/vault-action@v2.7.3
        with:
          method: jwt
          url: ${{ vars.VAULT_ADDR }}
          path: github
          role: whirlpool-installer
          secrets: |
            kv-v2/data/whirlpool/signer PAT_TOKEN | WHIRLPOOL_SIGNER_PAT_TOKEN ;
            kv-v2/data/whirlpool/signer REPOSITORY | WHIRLPOOL_SIGNER_REPOSITORY ;

      - run: npm install adm-zip
        if: inputs.sign_build == 'true'

      - name: Trigger signer workflow
        uses: actions/github-script@v7
        id: signer-workflow
        if: inputs.sign_build == 'true'
        with:
          github-token: ${{ steps.import-signing-secrets.outputs.WHIRLPOOL_SIGNER_PAT_TOKEN }}
          script: |
            const AdmZip = require('adm-zip');
            const fs = require('fs');
            const MAX_RETRY=7;
            const RETRY_TIMEOUT_S = 5 ;
            const now = new Date();

            const wait = (ms) => new Promise((res) => setTimeout(res, ms));

            const callWithRetry = async (fn, max_retry = MAX_RETRY, retry_timeout = RETRY_TIMEOUT_S * 1000, depth = 0) => {
                try {
                    const out = await fn();
                    if (out === undefined || out === null || (Array.isArray(out) && out.length === 0)) {
                        await wait(retry_timeout);
                        return callWithRetry(fn, max_retry, retry_timeout, depth + 1);
                    }
                    return out;
                } catch(e) {
                    if (depth > max_retry) {
                        throw e;
                    }
                    await wait(retry_timeout);
                    return callWithRetry(fn, max_retry, retry_timeout, depth + 1);
                }
            }

            const getWorkflowId = async (workflow_name) => {
                const _fetchWorkflow = async () => {
                    const workflows = await github.rest.actions.listWorkflowRuns({
                        owner: gh_info[0],
                        repo: gh_info[1],
                        workflow_id: "sign_file.yaml",
                        created: `>${now.toISOString()}`,
                    });
                    return workflows.data.workflow_runs.find(w => w.name === workflow_name);
                };
                const workflow = await callWithRetry(_fetchWorkflow);
                return workflow && workflow.id;
            }

            const workflow_final_status = [
                "completed",
                "cancelled",
                "failure",
                "neutral",
                "skipped",
                "stale",
                "success",
                "timed_out",
            ]

            const waitForWorkflowRunCompletion = async (run_id) => {
                const _waitForWorkflowRunCompletion = async () => {
                  const workflow = await github.rest.actions.getWorkflowRun({
                      owner: gh_info[0],
                      repo: gh_info[1],
                      run_id,
                  });
                    if (workflow && workflow_final_status.includes(workflow.data.status)) {
                        return workflow.data;
                    }
                    return null;
                };
                return await callWithRetry(_waitForWorkflowRunCompletion, 60, 60);
            }

            const getWorkflowArtifact = async (run_id, artifact_name) => {
               const _getWorkflowArtifact = async () => {
                   const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                       owner: gh_info[0],
                       repo: gh_info[1],
                       run_id,
                   })
                   if (!artifacts) return null;
                   return artifacts.data.artifacts.find(a => a.name === artifact_name);
               }
               return await callWithRetry(_getWorkflowArtifact);
            }

            const downloadArtifact = async (artifact_id, download_path) => {
               const zip = await github.rest.actions.downloadArtifact({
                   owner: gh_info[0],
                   repo: gh_info[1],
                   artifact_id,
                   archive_format: "zip"
               });
               fs.mkdirSync(download_path, { recursive: true });
               const adm = new AdmZip(Buffer.from(zip.data));
               adm.extractAllTo(download_path, true);
            } 

            // Get data
            const gh_info = "${{ steps.import-signing-secrets.outputs.WHIRLPOOL_SIGNER_REPOSITORY }}".split("/");
            const artifact_sas = "${{ steps.sas-url.outputs.sas }}";
            const artifact_name = "${{ needs.derive_info.outputs.package }}-${{ matrix.os.arch }}-${{ needs.derive_info.outputs.toolchain}}-v${{ needs.derive_info.outputs.version }}-signed${{ matrix.os.extension }}";
            const gh_artifact_name = "signed_artifacts";
            const temp_dir = String.raw`${{ runner.temp }}`;
            const dir_separator = temp_dir.indexOf("\\") == -1 ? "/" : "\\";
            const download_path = `${temp_dir}${dir_separator}signed_artifacts${dir_separator}${{ needs.derive_info.outputs.package }}${dir_separator}${{ needs.derive_info.outputs.release_channel }}`;
            const repository = "${{ github.repository }}";
            const run_id = "${{ github.run_id }}";

            // 1. Dispatch the workflow
            await github.rest.actions.createWorkflowDispatch({
                owner: gh_info[0],
                repo: gh_info[1],
                workflow_id: "sign_file.yaml",
                ref: "main",
                inputs: {
                    artifact_sas: artifact_sas,
                    artifact_name: artifact_name,
                    source_repository: repository,
                    source_run_id: run_id
                }
            });
            // 2. Get the workflow id
            const workflow_id = await getWorkflowId(`Sign ${artifact_name} ${repository} ${run_id}`);
            // 3. Wait for the workflow_completion
            const completed_workflow = await waitForWorkflowRunCompletion(workflow_id);
            // 4. Load workflow artifact
            const artifact = await getWorkflowArtifact(workflow_id, gh_artifact_name);
            // 5. Download artifact
            await downloadArtifact(artifact.id, download_path);
            return {
                status: completed_workflow.status,
                conclusion: completed_workflow.conclusion,
                url: completed_workflow.url,
                id: completed_workflow.id,
            }

      - name: Generate signed artifacts checksum linux
        if: matrix.os.name == 'ubuntu-latest' && inputs.sign_build == 'true'
        shell: bash
        run: |
          artifacts_dir=${{ runner.temp }}/signed_artifacts/${{ needs.derive_info.outputs.package }}/${{ needs.derive_info.outputs.release_channel }}
          sha512sum $artifacts_dir/${{ needs.derive_info.outputs.package }}-${{ matrix.os.arch }}-${{ needs.derive_info.outputs.toolchain}}-v${{ needs.derive_info.outputs.version }}-signed${{ matrix.os.extension }} | awk '{ print $1 }' >> $artifacts_dir/${{ needs.derive_info.outputs.package }}-${{ matrix.os.arch }}-${{ needs.derive_info.outputs.toolchain}}-v${{ needs.derive_info.outputs.version }}${{ matrix.os.extension }}-signed-sha-512.txt

      - name: Generate signed artifacts checksum windows
        if: matrix.os.name == 'windows-latest' && inputs.sign_build == 'true'
        shell: pwsh
        run: |
          $hash = Get-FileHash "${{ runner.temp }}\signed_artifacts\${{ needs.derive_info.outputs.package }}\${{ needs.derive_info.outputs.release_channel }}\${{  needs.derive_info.outputs.package }}-${{ matrix.os.arch }}-${{ needs.derive_info.outputs.toolchain}}-v${{ needs.derive_info.outputs.version }}-signed${{ matrix.os.extension }}" -Algorithm SHA512
          echo $hash.Hash >> "${{ runner.temp }}\signed_artifacts\${{ needs.derive_info.outputs.package }}\${{ needs.derive_info.outputs.release_channel }}\${{  needs.derive_info.outputs.package }}-${{ matrix.os.arch }}-${{ needs.derive_info.outputs.toolchain}}-v${{ needs.derive_info.outputs.version }}-signed-sha512.txt"

      - name: Upload signed artifacts to Azure Blob Upload
        if: inputs.sign_build == 'true'
        uses: LanceMcCarthy/Action-AzureBlobUpload@v2.2.1
        with:
          container_name: ${{ vars.ARTIFACTS_CONTAINER }}
          connection_string: ${{ secrets.ARTIFACTS_CONNECTION_STRING }}
          source_folder: ${{ runner.temp }}/signed_artifacts
          delete_if_exists: true

      - name: Upload bin to github artifacts
        uses: actions/upload-artifact@v4
        with:
          name: release-binaries
          path: ${{ runner.temp }}/bin_output

      - name: Upload signed bin to github artifacts
        if: inputs.sign_build == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: signed-binaries
          path: ${{ runner.temp }}/signed_artifacts
